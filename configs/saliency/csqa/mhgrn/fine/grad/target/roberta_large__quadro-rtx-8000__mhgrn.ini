[DEFAULT]
dataset : csqa
split_type : inhouse

task : saliency
arch : roberta_large

text_encoder_head : bos_token_mlp
text_in_dim : 1024
text_out_dim : 1024
text_hidden_dim : 1024
text_hidden_layers : 1
text_layer_norm : True
text_dropout : False

graph_encoder : mhgrn
sal_gnn_io_dim : 1024
sal_gnn_hidden_dim : 1024
sal_gnn_hidden_layers : 1
sal_gnn_layer_norm : True
sal_gnn_dropout : False
sal_gnn_layers : 1
sal_cls_hidden_dim : 1024
sal_cls_hidden_layers : 1
sal_cls_layer_norm : True
sal_cls_dropout : False
pos_weight : 1

sal_gnn_layer_type : mhgrn
graph_k : 2
graph_n_type : 3
graph_num_basis : 0
graph_gnn_layer_num : 1
graph_diag_decompose : True
graph_num_relation : 34
graph_gnn_dim : 100
graph_fc_dim : 200
graph_fc_layer_num : 0
graph_att_head_num : 2
graph_att_dim : 50
graph_att_layer_num : 1
graph_dropouti : 0.1
graph_dropoutg : 0.1
graph_dropoutf : 0.2
graph_init_range : 0.02
graph_eps : 1e-15
graph_init_rn : True
graph_init_identity : True
graph_freeze_ent_emb : True

ent_emb_dim : 1024
rel_emb_dim : 100

saliency_mode : fine
saliency_source : target
saliency_method : grad
save_saliency : False
top_k : 10

max_epochs : 100
train_batch_size : 8
eval_batch_size : 8
accumulate_grad_batches : 4

text_lr : 1e-5
graph_lr : 1e-4
optimizer : radam
lr_scheduler : fixed
warmup_updates : 1000

num_workers : 10
gpus : 1

seed : 0
fp16 : True
